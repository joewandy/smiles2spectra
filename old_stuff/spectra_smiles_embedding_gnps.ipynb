{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Joint embedding of fragmentation spectra and chemical compounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.callbacks import History, ReduceLROnPlateau, EarlyStopping\n",
    "from keras import backend as K\n",
    "from livelossplot import PlotLossesKeras\n",
    "\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem.Draw import IPythonConsole #Needed to show molecules\n",
    "from rdkit.Chem.Draw.MolDrawing import MolDrawing, DrawingOptions #Only needed if modifying default\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit import Chem, DataStructs\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler, normalize\n",
    "\n",
    "from rdkit.Chem.Fingerprints import FingerprintMols\n",
    "from rdkit.Chem import MACCSkeys\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pickle\n",
    "import csv\n",
    "\n",
    "from functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load GNPS+Massbank data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data contains SMILES of known molecules and also their fragmentation spectra from massbank + gnps.\n",
    "\n",
    "Collision energies are merged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('../data/gnps_massbank_data.p', 'rb') as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['spectra'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('smiles_list.smi', 'w') as f:\n",
    "#     for smile in data['smiles']:\n",
    "#         f.write(smile + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create spectra embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load a simple dense model. This was trained on the training data and is used to map\n",
    "\n",
    "- From: fragmentation spectra \n",
    "- To: 100-dimensional representation\n",
    "\n",
    "TODO: represent spectra as their LDA topic decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_spectra_autoencoder = keras.models.load_model('../models/spectra_autoencoder_gnps_massbank.h5')\n",
    "input_spectra_encoder = keras.models.load_model('../models/spectra_encoder_gnps_massbank.h5')\n",
    "input_spectra_decoder = keras.models.load_model('../models/spectra_decoder_gnps_massbank.h5')\n",
    "input_spectra_autoencoder.summary()\n",
    "svg = plot_model_in_notebook(input_spectra_autoencoder)\n",
    "svg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectra_latent = input_spectra_encoder.predict(data['spectra'])\n",
    "print(spectra_latent.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spectra_decoded = input_spectra_decoder.predict(spectra_latent)\n",
    "# for idx in range(10):\n",
    "#     pos = np.nonzero(data['spectra'][idx])\n",
    "# #     print(data['vocab'][pos])\n",
    "#     plt.plot(data['vocab'], data['spectra'][idx])\n",
    "#     plt.plot(data['vocab'], -spectra_decoded[idx])\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create  Fingerprints of Molecules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smiles_to_fingerprints(smiles):\n",
    "    max_length = 0\n",
    "    valid_idx = []\n",
    "    fingerprints = []\n",
    "    for i in range(len(smiles)):\n",
    "        smile = smiles[i]\n",
    "        mol = Chem.MolFromSmiles(smile)\n",
    "        try:\n",
    "            # fp = FingerprintMols.FingerprintMol(mol)\n",
    "            # fp = MACCSkeys.GenMACCSKeys(mol)\n",
    "            fp = AllChem.GetMorganFingerprintAsBitVect(mol, 3, nBits=2048)\n",
    "            bits = np.array(list(fp.GetOnBits()))\n",
    "            if max(bits) > max_length:\n",
    "                max_length = max(bits)\n",
    "            valid_idx.append(i)\n",
    "            fingerprints.append(bits)\n",
    "        except Exception:\n",
    "            print('Invalid smile', smiles[i])\n",
    "            continue\n",
    "\n",
    "    fingerprint_arr = np.zeros((len(fingerprints), max_length+1))\n",
    "    for i in range(len(fingerprints)):\n",
    "        fingerprint = fingerprints[i]\n",
    "        for bit in fingerprint:\n",
    "            fingerprint_arr[i][bit] = 1\n",
    "\n",
    "    return fingerprint_arr, valid_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fingerprint_arr, valid_idx = smiles_to_fingerprints(data['smiles'])\n",
    "fingerprint_arr, valid_idx = smiles_to_fingerprints(data['smiles'])\n",
    "assert len(data['smiles']) == len(data['spectra'])\n",
    "spectra = data['spectra'][valid_idx]\n",
    "smiles = data['smiles'][valid_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load simon's fingerprint\n",
    "# fprints = {}\n",
    "# with open('../data/smiles_sub.csv','r') as f:\n",
    "#     reader = csv.reader(f)\n",
    "#     for line in reader:\n",
    "#         fprints[line[0]] = [int(i) for i in line[1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fingerprint_arr = np.zeros((len(smiles), 306+1))\n",
    "# for i in range(len(smiles)):\n",
    "#     smile = smiles[i]\n",
    "#     fingerprint = fprints[smile]\n",
    "#     for bit in fingerprint:\n",
    "#         fingerprint_arr[i][bit] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectra_latent = input_spectra_encoder.predict(spectra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fingerprint_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectra_latent[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fingerprint_arr[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try joint embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Objective: build a model that projects spectra and molecules in the same representation space, so that a spectra is close to its molecule in that space, and far away from dissimilar spectra and dissimilar molecules.\n",
    "\n",
    "Each training point is a triplet of:\n",
    "- fragmentation spectra, also called an anchor\n",
    "- compound correctly associated to that spectra, also called the positive example\n",
    "- compound incorrectly associated to that spectra, also called the negative example\n",
    "\n",
    "During training, we compute the scores of the anchor to the positive and negative examples (dot products). The optimisation objective is to maximise total positive scores and minimise total negative scores. Then for each training step, we shuffle the negative examples randomly.\n",
    "\n",
    "See:\n",
    "\n",
    "- https://pageperso.lis-lab.fr/benoit.favre/dl4nlp/tutorials/05-caption.pdf\n",
    "- https://arxiv.org/abs/1511.06078"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding_model(input_dim_spectra, input_dim_molecule, embedding_dim):\n",
    "    \n",
    "    spectra_input = Input(shape=(input_dim_spectra,), name='spectra_input')\n",
    "    smile_input = Input(shape=(input_dim_molecule,), name='positive_molecule')\n",
    "    noise_input = Input(shape=(input_dim_molecule,), name='negative_molecule')\n",
    "        \n",
    "    spectra_pipeline = Dense(embedding_dim, use_bias=False, name='spectra_weights')(spectra_input)\n",
    "    spectra_pipeline = BatchNormalization(name='bn1')(spectra_pipeline)\n",
    "    spectra_pipeline = Activation('relu', name='relu1')(spectra_pipeline)\n",
    "    spectra_pipeline = Dense(embedding_dim, activation='relu', name='spectra_weights2')(spectra_pipeline)\n",
    "\n",
    "    smile_dense1 = Dense(embedding_dim, use_bias=False, name='molecule_weights') \n",
    "    bn = BatchNormalization(name='bn2')\n",
    "    activation = Activation('relu', name='relu2')\n",
    "    smile_dense2 = Dense(embedding_dim, activation='relu', name='molecule_weights2')\n",
    "    smile_pipeline = smile_dense2(activation(bn(smile_dense1(smile_input))))\n",
    "    noise_pipeline = smile_dense2(activation(bn(smile_dense1(noise_input))))        \n",
    "\n",
    "    positive_pair = dot([spectra_pipeline, smile_pipeline], axes=1)\n",
    "    negative_pair = dot([spectra_pipeline, noise_pipeline], axes=1)\n",
    "    concat_output = concatenate([positive_pair, negative_pair])\n",
    "    embedding_model = Model(inputs=[spectra_input, smile_input, noise_input], outputs=concat_output)\n",
    "\n",
    "    l2_norm1 = Lambda(lambda  x: K.l2_normalize(x, axis=1))   \n",
    "    l2_norm2 = Lambda(lambda  x: K.l2_normalize(x, axis=1))       \n",
    "    spectra_encoder = Model(inputs=spectra_input, outputs=l2_norm1(spectra_pipeline))\n",
    "    smile_encoder = Model(inputs=smile_input, outputs=l2_norm2(smile_pipeline))\n",
    "    \n",
    "    # also see https://github.com/keras-team/keras/issues/150\n",
    "    def custom_loss(y_true, y_pred):\n",
    "        positive = y_pred[:,0]\n",
    "        negative = y_pred[:,1]\n",
    "        return K.sum(K.maximum(0., 1. - positive + negative))\n",
    "    \n",
    "    def accuracy(y_true, y_pred):\n",
    "        positive = y_pred[:,0]\n",
    "        negative = y_pred[:,1]\n",
    "        return K.mean(positive > negative)\n",
    "    \n",
    "    embedding_model.compile(loss=custom_loss, optimizer='adam', metrics=[accuracy])\n",
    "    return embedding_model, spectra_encoder, smile_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 50\n",
    "input_dim_spectra = spectra_latent.shape[1]\n",
    "input_dim_molecule = fingerprint_arr.shape[1]\n",
    "joint_embedding_model, spectra_encoder, smile_encoder = get_embedding_model(input_dim_spectra, \n",
    "                                                                            input_dim_molecule, \n",
    "                                                                            EMBEDDING_DIM)\n",
    "joint_embedding_model.summary()\n",
    "plot_model_in_notebook(joint_embedding_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparing training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_together(a, b, c, d):\n",
    "    assert len(a) == len(b)\n",
    "    assert len(a) == len(c)\n",
    "    assert len(a) == len(d)\n",
    "    p = np.random.permutation(len(a))\n",
    "    return a[p], b[p], c[p], d[p]\n",
    "\n",
    "spectra, spectra_latent, smiles, fingerprint_arr = shuffle_together(spectra, spectra_latent, smiles, fingerprint_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fingerprint_arr = normalize(fingerprint_arr, norm='l2', axis=1)\n",
    "spectra_latent = normalize(spectra_latent, norm='l2', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = int(len(spectra_latent) * 0.8)\n",
    "remaining = len(spectra_latent) - pos\n",
    "print(pos, remaining)\n",
    "\n",
    "noise = np.copy(fingerprint_arr)\n",
    "fake_labels = np.zeros((len(spectra_latent), 1))\n",
    "\n",
    "X_train = [spectra_latent[:pos], fingerprint_arr[:pos], noise[:pos]]\n",
    "Y_train = fake_labels[:pos]\n",
    "X_test = [spectra_latent[-remaining:], fingerprint_arr[-remaining:], noise[-remaining:]]\n",
    "Y_test = fake_labels[-remaining:]\n",
    "\n",
    "spectra_train = spectra[:pos]\n",
    "spectra_test = spectra[-remaining:]\n",
    "smiles_train = smiles[:pos]\n",
    "smiles_test = smiles[-remaining:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train[0].shape, X_train[1].shape, X_train[2].shape)\n",
    "print(X_test[0].shape, X_test[1].shape, X_test[2].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rlr = ReduceLROnPlateau(monitor='val_loss', factor=0.5,patience=10, min_lr=0.000001,\n",
    "#                         verbose=1, epsilon=1e-5)\n",
    "# early_stop = EarlyStopping(monitor='val_loss', min_delta=0, patience=3, verbose=1, mode='auto')\n",
    "# callbacks = [rlr, early_stop]\n",
    "\n",
    "# tensorboard = keras.callbacks.TensorBoard(log_dir='./graph', histogram_freq=0,  \n",
    "#           write_graph=True, write_images=True)\n",
    "# callbacks = [rlr, early_stop, tensorboard]\n",
    "# if is_notebook():\n",
    "#     callbacks.append(PlotLossesKeras())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: generate mini-batch properly https://stackoverflow.com/questions/48568062/keras-custom-infinite-data-generator-with-shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# actual training\n",
    "for epoch in range(1000):\n",
    "    if epoch % 100 == 0:\n",
    "        print('\\nIteration %d' % epoch)\n",
    "        verbose=1\n",
    "    else:\n",
    "        verbose=0\n",
    "    np.random.shuffle(noise) # shuffle mismatched smiles\n",
    "    joint_embedding_model.fit(X_train, Y_train,\n",
    "        validation_data=[X_test, Y_test], epochs=1,\n",
    "        batch_size=32, verbose=verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# joint_embedding_model.save('../models/joint_embedding_gnps_massbank.h5')\n",
    "# spectra_encoder.save('../models/joint_spectra_encoder_gnps_massbank.h5')\n",
    "# smile_encoder.save('../models/joint_smile_encoder_gnps_massbank.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualise the joint embedding results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualise_embedding(spectra_data, molecule_data, spectra_encoder, smile_encoder):\n",
    "    \n",
    "    embedded_spectra = spectra_encoder.predict(spectra_data)\n",
    "    embedded_molecules = smile_encoder.predict(molecule_data)\n",
    "    embedded_combined = np.concatenate([embedded_spectra, embedded_molecules], axis=0)\n",
    "    \n",
    "    PCA_COMPONENTS = 25\n",
    "    pca = PCA(n_components = PCA_COMPONENTS)\n",
    "    latent_proj = pca.fit_transform(embedded_combined)\n",
    "    covariance = pca.get_covariance()\n",
    "    evr = pca.explained_variance_ratio_\n",
    "    print('Explained variations -- first two PCs: %.2f' % (evr[0] + evr[1]))\n",
    "    print('Explained variations -- all components: %.2f' % np.sum(evr))\n",
    "    print(evr)\n",
    "        \n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.scatter(latent_proj[0:len(embedded_spectra), 0], latent_proj[0:len(embedded_spectra), 1], marker='x', c='red', s=1)\n",
    "    plt.scatter(latent_proj[len(embedded_spectra)+1:, 0], latent_proj[len(embedded_spectra)+1:, 1], marker='.', c='blue', s=1)\n",
    "    plt.title('Joint embedding of fragmentation spectra (red) and molecules (blue)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualise embedding on training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualise_embedding(X_train[0], X_train[1], spectra_encoder, smile_encoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualise embedding on testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualise_embedding(X_test[0], X_test[1], spectra_encoder, smile_encoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded_spectra = spectra_encoder.predict(X_test[0])\n",
    "embedded_molecules = smile_encoder.predict(X_test[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = embedded_spectra[0]\n",
    "print(x)\n",
    "print(np.dot(x, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (8,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = np.dot(embedded_spectra, embedded_molecules.T)\n",
    "print(scores.shape)\n",
    "plt.matshow(scores)\n",
    "plt.colorbar()\n",
    "plt.xlabel('molecules')\n",
    "plt.ylabel('spectra')\n",
    "plt.title('Dot product')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall_at(n, scores, verbose=False):\n",
    "    found = 0.0\n",
    "    total = len(scores)\n",
    "    results = {}\n",
    "    for i in range(total):\n",
    "        row = scores[i]\n",
    "        max_idx = row.argsort()[-n:][::-1]\n",
    "        if i in max_idx:\n",
    "            found += 1\n",
    "            correct = True\n",
    "        else:\n",
    "            correct = False\n",
    "        retrieved = list(zip(max_idx, row[max_idx]))\n",
    "        if verbose:\n",
    "            print(i, correct, retrieved)\n",
    "        results[i] = retrieved\n",
    "    precision = found/total\n",
    "    return precision, found, total, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prec, found, total, results = recall_at(10, scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Found %d/%d (%.2f)' % (found, total, prec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_spectra_and_molecule(idx, spectra, smiles):    \n",
    "    pos = np.nonzero(spectra[idx])\n",
    "    plt.plot(data['vocab'], spectra[idx])\n",
    "    plt.show()\n",
    "    smile = smiles[idx]    \n",
    "    print(smile)\n",
    "    mol = Chem.MolFromSmiles(smile)\n",
    "    mol_drawing = Draw.MolToMPL(mol, size=(150, 150))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(idx, spectra_test, smiles_test, results):\n",
    "    plt.rcParams['figure.figsize'] = (4,4)\n",
    "    \n",
    "    print('Query')\n",
    "    plot_spectra_and_molecule(idx, spectra_test, smiles_test)\n",
    "    \n",
    "    print(\"Retrieved\")\n",
    "    retrieved = results[idx]\n",
    "    for j, score in retrieved:\n",
    "        print('Molecule %d score %.2f' % (j, score))\n",
    "        plot_spectra_and_molecule(j, spectra_test, smiles_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plot_results(12, spectra_test, smiles_test, results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add decoy compounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import h5py\n",
    "decoy_data = pandas.read_hdf('/Users/joewandy/Dropbox/Analysis/autoencoder/data/pubchem_100k.h5', 'table')\n",
    "decoy_smiles = decoy_data['structure'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoy_fingerprint_arr, valid_decoy_idx = smiles_to_fingerprints(decoy_smiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_decoy_smiles = decoy_smiles[valid_decoy_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoy_fingerprint_arr = normalize(decoy_fingerprint_arr, norm='l2', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded_decoy_molecules = smile_encoder.predict(decoy_fingerprint_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recalls = []\n",
    "increase = 10000\n",
    "decoy_counts = list(range(0, len(valid_decoy_smiles)+increase, increase))\n",
    "for num_decoy in decoy_counts:\n",
    "    combined_molecules = np.concatenate([embedded_molecules, embedded_decoy_molecules[0:num_decoy],], axis=0)    \n",
    "    scores = np.dot(embedded_spectra, combined_molecules.T)\n",
    "    recall, found, total, results = recall_at(10, scores)\n",
    "    recalls.append(recall)\n",
    "    print('%.2f %d/%d %s' % (recall, found, total, scores.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(decoy_counts, recalls, linestyle='--', marker='o', color='b')\n",
    "plt.title('Recall@10 with increasing decoy compounds')\n",
    "plt.ylabel('Recall@10')\n",
    "plt.xlabel('#decoy')\n",
    "plt.grid(b=True, which='both')\n",
    "plt.yticks(np.arange(min(recalls), max(recalls)+0.05, 0.05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:smiles2spectra]",
   "language": "python",
   "name": "conda-env-smiles2spectra-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
