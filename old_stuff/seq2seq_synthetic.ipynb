{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seq2seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "import pylab as plt\n",
    "import numpy as np\n",
    "\n",
    "from pipeline import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test with synthetic data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We generate some easy synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 5000\n",
    "n_timesteps_in = 5\n",
    "n_timesteps_out = 30\n",
    "n_features_in = 10\n",
    "n_features_out = 26\n",
    "train = False\n",
    "weights_file = '../models/test_synthetic_weights.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = generate_sequences(n_samples, n_timesteps_in, n_timesteps_out, n_features_in, n_features_out, \n",
    "                          delete=0, multiply=1, permute=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab (11) ['PAD', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
      "vocab (13) ['PAD', '\\t', '\\n', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J']\n"
     ]
    }
   ],
   "source": [
    "encoded_X = encode(X)\n",
    "encoded_y = encode(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 7 10  8 10  4] --> [ 1  9 12 10 12  6  2]\n",
      "[7 5 4 3 8] --> [ 1  9  7  6  5 10  2]\n",
      "[9 6 7 3 5] --> [ 1 11  8  9  5  7  2]\n",
      "[ 8 10  1  4  5] --> [ 1 10 12  3  6  7  2]\n",
      "[4 4 3 2 2] --> [1 6 6 5 4 4 2]\n",
      "[3 8 5 4 4] --> [ 1  5 10  7  6  6  2]\n",
      "[5 5 5 7 1] --> [1 7 7 7 9 3 2]\n",
      "[ 8  4  1 10  9] --> [ 1 10  6  3 12 11  2]\n",
      "[1 5 9 2 6] --> [ 1  3  7 11  4  8  2]\n",
      "[9 3 8 1 6] --> [ 1 11  5 10  3  8  2]\n",
      "[6 7 4 9 1] --> [ 1  8  9  6 11  3  2]\n",
      "[ 2  1  6  8 10] --> [ 1  4  3  8 10 12  2]\n",
      "[ 2  3  7  1 10] --> [ 1  4  5  9  3 12  2]\n",
      "[8 5 6 5 9] --> [ 1 10  7  8  7 11  2]\n",
      "[6 3 6 9 8] --> [ 1  8  5  8 11 10  2]\n",
      "[ 3  3 10  2  5] --> [ 1  5  5 12  4  7  2]\n",
      "[ 6 10  6  7  3] --> [ 1  8 12  8  9  5  2]\n",
      "[6 6 8 8 4] --> [ 1  8  8 10 10  6  2]\n",
      "[10  1  9 10  7] --> [ 1 12  3 11 12  9  2]\n",
      "[5 9 4 7 8] --> [ 1  7 11  6  9 10  2]\n",
      "[8 5 4 4 3] --> [ 1 10  7  6  6  5  2]\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for source, target in zip(encoded_X.int_encoded, encoded_y.int_encoded):\n",
    "    print(source, '-->', target)\n",
    "    i += 1\n",
    "    if i > 20:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_choice = 1\n",
    "latent_dim = 32\n",
    "batch_size = 32\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, None, 11)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, None, 13)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "masking_1 (Masking)             (None, None, 11)     0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "masking_2 (Masking)             (None, None, 13)     0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 32), (None,  5632        masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, None, 32), ( 5888        masking_2[0][0]                  \n",
      "                                                                 lstm_1[0][1]                     \n",
      "                                                                 lstm_1[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, None, 13)     429         lstm_2[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 11,949\n",
      "Trainable params: 11,949\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Loading model weights from ../models/test_synthetic_weights.h5\n"
     ]
    }
   ],
   "source": [
    "if train:\n",
    "    model, additional = get_model(model_choice, latent_dim, \n",
    "                                  encoded_X.max_timesteps, encoded_y.max_timesteps, \n",
    "                                  encoded_X.max_features, encoded_y.max_features)    \n",
    "    train_model(model, encoded_X, encoded_y, model_choice, \n",
    "                latent_dim, batch_size, epochs,\n",
    "                encoded_X.max_timesteps, encoded_y.max_timesteps, \n",
    "                encoded_X.max_features, encoded_y.max_features)\n",
    "    model.save_weights(weights_file)\n",
    "else:\n",
    "    model, additional = get_model(model_choice, latent_dim, \n",
    "                                  encoded_X.max_timesteps, encoded_y.max_timesteps, \n",
    "                                  encoded_X.max_features, encoded_y.max_features,\n",
    "                                  weights_file=weights_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate some new data to evaluate performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 10\n",
    "X_new, y_new = generate_sequences(n_samples, n_timesteps_in, n_timesteps_out, n_features_in, n_features_out, \n",
    "                          delete=0, multiply=1, permute=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query     \"62081\"\n",
      "Actual    \"GCAIB\"\n",
      "Predicted \"GCAIB\"\n",
      "['G', 'C', 'A', 'I', 'B', '\\n']\n",
      "\n",
      "Query     \"62217\"\n",
      "Actual    \"GCCBH\"\n",
      "Predicted \"GCCBH\"\n",
      "['G', 'C', 'C', 'B', 'H', '\\n']\n",
      "\n",
      "Query     \"33394\"\n",
      "Actual    \"DDDJE\"\n",
      "Predicted \"DDDJE\"\n",
      "['D', 'D', 'D', 'J', 'E', '\\n']\n",
      "\n",
      "Query     \"74464\"\n",
      "Actual    \"HEEGE\"\n",
      "Predicted \"HEEGE\"\n",
      "['H', 'E', 'E', 'G', 'E', '\\n']\n",
      "\n",
      "Query     \"46984\"\n",
      "Actual    \"EGJIE\"\n",
      "Predicted \"EGJIE\"\n",
      "['E', 'G', 'J', 'I', 'E', '\\n']\n",
      "\n",
      "Query     \"53650\"\n",
      "Actual    \"FDGFA\"\n",
      "Predicted \"FDGFA\"\n",
      "['F', 'D', 'G', 'F', 'A', '\\n']\n",
      "\n",
      "Query     \"52002\"\n",
      "Actual    \"FCAAC\"\n",
      "Predicted \"FCAAC\"\n",
      "['F', 'C', 'A', 'A', 'C', '\\n']\n",
      "\n",
      "Query     \"64489\"\n",
      "Actual    \"GEEIJ\"\n",
      "Predicted \"GEEIJ\"\n",
      "['G', 'E', 'E', 'I', 'J', '\\n']\n",
      "\n",
      "Query     \"13404\"\n",
      "Actual    \"BDEAE\"\n",
      "Predicted \"BDEAE\"\n",
      "['B', 'D', 'E', 'A', 'E', '\\n']\n",
      "\n",
      "Query     \"24356\"\n",
      "Actual    \"CEDFG\"\n",
      "Predicted \"CEDFG\"\n",
      "['C', 'E', 'D', 'F', 'G', '\\n']\n",
      "\n",
      "correct 10\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(X_new, y_new, encoded_X, encoded_y, model, model_choice, additional, sep='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also check on some training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "nums = [x for x in range(len(X))]\n",
    "random.shuffle(nums)\n",
    "X_new = []\n",
    "y_new = []\n",
    "for i in nums[0:20]:\n",
    "    X_new.append(X[i])\n",
    "    y_new.append(y[i])\n",
    "X_new = np.array(X_new)\n",
    "y_new = np.array(y_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query     \"01815\"\n",
      "Actual    \"ABIBF\"\n",
      "Predicted \"ABIBF\"\n",
      "['A', 'B', 'I', 'B', 'F', '\\n']\n",
      "\n",
      "Query     \"02690\"\n",
      "Actual    \"ACGJA\"\n",
      "Predicted \"ACGJA\"\n",
      "['A', 'C', 'G', 'J', 'A', '\\n']\n",
      "\n",
      "Query     \"48367\"\n",
      "Actual    \"EIDGH\"\n",
      "Predicted \"EIDGH\"\n",
      "['E', 'I', 'D', 'G', 'H', '\\n']\n",
      "\n",
      "Query     \"16840\"\n",
      "Actual    \"BGIEA\"\n",
      "Predicted \"BGIEA\"\n",
      "['B', 'G', 'I', 'E', 'A', '\\n']\n",
      "\n",
      "Query     \"41655\"\n",
      "Actual    \"EBGFF\"\n",
      "Predicted \"EBGFF\"\n",
      "['E', 'B', 'G', 'F', 'F', '\\n']\n",
      "\n",
      "Query     \"64550\"\n",
      "Actual    \"GEFFA\"\n",
      "Predicted \"GEFFA\"\n",
      "['G', 'E', 'F', 'F', 'A', '\\n']\n",
      "\n",
      "Query     \"29139\"\n",
      "Actual    \"CJBDJ\"\n",
      "Predicted \"CJBDJ\"\n",
      "['C', 'J', 'B', 'D', 'J', '\\n']\n",
      "\n",
      "Query     \"80006\"\n",
      "Actual    \"IAAAG\"\n",
      "Predicted \"IAAAG\"\n",
      "['I', 'A', 'A', 'A', 'G', '\\n']\n",
      "\n",
      "Query     \"63432\"\n",
      "Actual    \"GDEDC\"\n",
      "Predicted \"GDEDC\"\n",
      "['G', 'D', 'E', 'D', 'C', '\\n']\n",
      "\n",
      "Query     \"48771\"\n",
      "Actual    \"EIHHB\"\n",
      "Predicted \"EIHHB\"\n",
      "['E', 'I', 'H', 'H', 'B', '\\n']\n",
      "\n",
      "Query     \"81164\"\n",
      "Actual    \"IBBGE\"\n",
      "Predicted \"IBBGE\"\n",
      "['I', 'B', 'B', 'G', 'E', '\\n']\n",
      "\n",
      "Query     \"25468\"\n",
      "Actual    \"CFEGI\"\n",
      "Predicted \"CFEGI\"\n",
      "['C', 'F', 'E', 'G', 'I', '\\n']\n",
      "\n",
      "Query     \"74813\"\n",
      "Actual    \"HEIBD\"\n",
      "Predicted \"HEIBD\"\n",
      "['H', 'E', 'I', 'B', 'D', '\\n']\n",
      "\n",
      "Query     \"98099\"\n",
      "Actual    \"JIAJJ\"\n",
      "Predicted \"JIAJJ\"\n",
      "['J', 'I', 'A', 'J', 'J', '\\n']\n",
      "\n",
      "Query     \"08702\"\n",
      "Actual    \"AIHAC\"\n",
      "Predicted \"AIHAC\"\n",
      "['A', 'I', 'H', 'A', 'C', '\\n']\n",
      "\n",
      "Query     \"83451\"\n",
      "Actual    \"IDEFB\"\n",
      "Predicted \"IDEFB\"\n",
      "['I', 'D', 'E', 'F', 'B', '\\n']\n",
      "\n",
      "Query     \"03795\"\n",
      "Actual    \"ADHJF\"\n",
      "Predicted \"ADHJF\"\n",
      "['A', 'D', 'H', 'J', 'F', '\\n']\n",
      "\n",
      "Query     \"67761\"\n",
      "Actual    \"GHHGB\"\n",
      "Predicted \"GHHGB\"\n",
      "['G', 'H', 'H', 'G', 'B', '\\n']\n",
      "\n",
      "Query     \"98589\"\n",
      "Actual    \"JIFIJ\"\n",
      "Predicted \"JIFIJ\"\n",
      "['J', 'I', 'F', 'I', 'J', '\\n']\n",
      "\n",
      "Query     \"10530\"\n",
      "Actual    \"BAFDA\"\n",
      "Predicted \"BAFDA\"\n",
      "['B', 'A', 'F', 'D', 'A', '\\n']\n",
      "\n",
      "correct 20\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(X_new, y_new, encoded_X, encoded_y, model, model_choice, additional, sep='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:smiles2spectra]",
   "language": "python",
   "name": "conda-env-smiles2spectra-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
